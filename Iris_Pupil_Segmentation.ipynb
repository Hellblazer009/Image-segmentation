import os
import sys
import random
import warnings

import numpy as np
import pandas as pd
import tensorflow as tf
!pip install tensorflow_addons
import tensorflow_addons as tfa
import cv2

import matplotlib.pyplot as plt

from tqdm import tqdm
from itertools import chain
from skimage.io import imread, imshow, imread_collection, concatenate_images
from skimage.transform import resize
from skimage.morphology import label

from keras.models import Model, load_model
from keras.layers import Input
from keras.layers.core import Dropout, Lambda
from keras.layers.convolutional import Conv2D, Conv2DTranspose
from keras.layers.pooling import MaxPooling2D
from keras.layers import concatenate
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras import backend as K

warnings.filterwarnings('ignore', category=UserWarning, module='skimage')
seed = 69
random.seed = seed
np.random.seed = seed

# specify image dimensions to for consideration and subsequent u-net architecture design
# IMG_WIDTH = 128
# IMG_HEIGHT = 128
IMG_WIDTH = 224
IMG_HEIGHT = 160
# img_height = 160
# img_width = 224
IMG_CHANNELS = 3
TRAIN_PATH = '/content/drive/MyDrive/ColabNotebooks/L2/training_set' # directory for training dataset
TEST_PATH = '/content/drive/MyDrive/ColabNotebooks/L2/testing_set' # directory for test dataset

# Preprocess trainining images and masks
train_masks_ids = os.listdir("/content/drive/MyDrive/ColabNotebooks/L2/training_set/masks")
train_images_ids = os.listdir("/content/drive/MyDrive/ColabNotebooks/L2/training_set/images")
# sort to match file names
train_masks_ids.sort()
train_images_ids.sort()

# initialize with zeros
X_train = np.zeros((len(train_masks_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.float32)
Y_train = np.zeros((len(train_masks_ids), IMG_HEIGHT, IMG_WIDTH), dtype=np.float32)
print('train images and masks')
sys.stdout.flush()

for n, id_ in tqdm(enumerate(train_masks_ids), total=len(train_masks_ids)):
    path = TRAIN_PATH
    img = imread(path + '/images/' + id_ )[:,:,:IMG_CHANNELS]
    img = resize(img, (IMG_HEIGHT, IMG_WIDTH)) #, mode='constant', preserve_range=True)
    # array = tf.keras.preprocessing.image.img_to_array(img)
    # img_n = tf.cast(array, tf.float32)
    # img_n /= 255
    # img = tf.keras.preprocessing.image.array_to_img(img_n)
    X_train[n] = img
    
    mask_ = imread(path + '/masks/' + id_ )
    mask_ = resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)
    # mask_array = tf.keras.preprocessing.image.img_to_array(mask_)
    # mask_n = tf.cast(mask_array, tf.float32)
    # mask_n /= 2
    # mask_ = tf.keras.preprocessing.image.array_to_img(mask_n)
    Y_train[n] = mask_

# Preprocess test images and masks
test_masks_ids = os.listdir("/content/drive/MyDrive/L2/testing_set/masks")
test_images_ids = os.listdir("/content/drive/MyDrive/L2/testing_set/images")
# sort to match file names
test_masks_ids.sort()
test_images_ids.sort()

X_test = np.zeros((len(test_images_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.float32)
Y_test = np.zeros((len(test_masks_ids), IMG_HEIGHT, IMG_WIDTH), dtype=np.float32)

print('test images')
sys.stdout.flush()
for n, id_ in tqdm(enumerate(test_images_ids), total=len(test_images_ids)):
    path = TEST_PATH 
    img = imread(path + '/images/' + id_)[:,:,:IMG_CHANNELS]
    img = resize(img, (IMG_HEIGHT, IMG_WIDTH)) #, mode='constant', preserve_range=True)
    # array = tf.keras.preprocessing.image.img_to_array(img)
    # img_n = tf.cast(array, tf.float32)
    # img_n /= 255
    # img = tf.keras.preprocessing.image.array_to_img(img_n)
    X_test[n] = img

    mask_ = imread(path + '/masks/' + id_ )
    mask_ = resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)
    Y_test[n] = mask_

# DEBUG: Verify some samples through visual inspection
# *IGNORE ON FINAL RUN*

# # for n, id_ in tqdm(enumerate(train_masks_ids), total=len(train_masks_ids)):
# #     path = TRAIN_PATH
# #     print(id_)
#
i = random.randint(0, len(train_masks_ids))
id_ = train_masks_ids[i]
img = imread(TRAIN_PATH + '/images/' + id_ )[:,:,:IMG_CHANNELS]

img1 = resize(img, (128,128))#, mode='constant', preserve_range=True)

imshow(img)
plt.show()

# imshow(img1)
# plt.show()
# tf.reduce_max(Y_train[i])

# U-NET MODEL
# specs: 
# Check model summary to verify architecture specs
inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
s = Lambda(lambda x: x / 255) (inputs)

c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)
c1 = Dropout(0.1) (c1)
c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)
p1 = MaxPooling2D((2, 2)) (c1)

c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)
c2 = Dropout(0.1) (c2)
c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)
p2 = MaxPooling2D((2, 2)) (c2)

c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)
c3 = Dropout(0.2) (c3)
c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)
p3 = MaxPooling2D((2, 2)) (c3)

c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)
c4 = Dropout(0.2) (c4)
c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)
p4 = MaxPooling2D(pool_size=(2, 2)) (c4)

c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)
c5 = Dropout(0.3) (c5)
c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)

u6 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same') (c5)
u6 = concatenate([u6, c4])
c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)
c6 = Dropout(0.2) (c6)
c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)

u7 = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same') (c6)
u7 = concatenate([u7, c3])
c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)
c7 = Dropout(0.2) (c7)
c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)

u8 = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same') (c7)
u8 = concatenate([u8, c2])
c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)
c8 = Dropout(0.1) (c8)
c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)

u9 = Conv2DTranspose(16, (3, 3), strides=(2, 2), padding='same') (c8)
u9 = concatenate([u9, c1], axis=3)
c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)
c9 = Dropout(0.1) (c9)
c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)

outputs = Conv2D(3, (1, 1), padding="same", activation='sigmoid') (c9)
# outputs = Conv2D(1, (1, 1), padding="same", activation='sigmoid') (c9)

model = Model(inputs=[inputs], outputs=[outputs])
# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.MeanIoU(num_classes=2)])
model.compile(optimizer='adam', loss='SparseCategoricalCrossentropy', metrics=['accuracy'])

model.summary()

# training the model

# checkpointer for saving best 
# early stopper callback

results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=50, callbacks=None) 
                    # callbacks=[earlystopper, checkpointer]) maybe

# output is a 3 channel mask, consolidate into a single channel mask
def create_mask(pred_arr):
  temp_mask = np.zeros((IMG_HEIGHT, IMG_WIDTH), dtype=np.float32)
  for i in range(IMG_HEIGHT):
    for j in range(IMG_WIDTH):
      if(pred_arr[i,j,0] >= pred_arr[i,j,1]):
        if(pred_arr[i,j,0] >= pred_arr[i,j,2]):
          temp_mask[i,j] = 0
        else:
          temp_mask[i,j] = 2
      else:
        if(pred_arr[i,j,1] >= pred_arr[i,j,2]):
          temp_mask[i,j] = 1
        else:
          temp_mask[i,j] = 2
  
  return temp_mask


# Run predictions
preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)
preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)
preds_test = model.predict(X_test, verbose=1)


# masks for training predictions
predicted_mask_train = np.zeros((len(preds_train),IMG_HEIGHT,IMG_WIDTH),dtype=np.int32)
for i in range(len(preds_train)):
  predicted_mask_train[i] = create_mask(preds_train[i])

# masks for validation predictions
predicted_mask_val = np.zeros((len(preds_val),IMG_HEIGHT,IMG_WIDTH),dtype=np.int32)
for i in range(len(preds_val)):
  predicted_mask_val[i] = create_mask(preds_val[i])

# masks for test predictions
predicted_mask_test = np.zeros((len(preds_test),IMG_HEIGHT,IMG_WIDTH),dtype=np.int32)
for i in range(10):
  predicted_mask_test[i] = create_mask(preds_test[i])



print('Done predicting! \n')

# Filter the predicted mask for improving inconsistencies

filt_predicted_mask_test = np.zeros((len(X_test),IMG_HEIGHT, IMG_WIDTH), dtype=np.float32)
for i in range(len(X_test)):
  # filt_predicted_mask_test = cv2.GaussianBlur(predicted_mask_test[i],(3,3),0)
  # filt_predicted_mask_test[i] = tfa.image.gaussian_filter2d(predicted_mask_test[i], (3,3), 1.0, 'CONSTANT', 0, None ) 
  filt_predicted_mask_test[i] = tfa.image.median_filter2d(predicted_mask_test[i], (3,3), 'CONSTANT', 0, None ) # salt and pepper
  filt_predicted_mask_test[i] = tfa.image.gaussian_filter2d(filt_predicted_mask_test[i], (3,3), 1.0, 'CONSTANT', 0, None ) # blurred



# Displaying Test case predictions:

for i in range(len(X_test)):
  fig = plt.figure()
  fig.set_figheight(15)
  fig.set_figwidth(15)
  
  plt.subplot(1,4,1)
  plt.title('Input Image')
  plt.imshow(X_test[i])
  plt.axis('off')

  plt.subplot(1,4,2)
  plt.title('Mask Ground Truth')
  plt.imshow(Y_test[i])
  plt.axis('off')

  plt.subplot(1,4,3)
  plt.title('Mask Predicted')
  plt.imshow(predicted_mask_test[i])
  plt.axis('off')

  plt.subplot(1,4,4)
  plt.title('Filterd Mask Predicted')
  plt.imshow(filt_predicted_mask_test[i])
  plt.axis('off')

  plt.show()

# training data results:

for i in range(10):
  fig = plt.figure()
  fig.set_figheight(15)
  fig.set_figwidth(15)
  
  plt.subplot(1,3,1)
  plt.title('Input Image')
  plt.imshow(X_train[i])
  plt.axis('off')

  plt.subplot(1,3,2)
  plt.title('Mask Ground Truth')
  plt.imshow(Y_train[i])
  plt.axis('off')

  plt.subplot(1,3,3)
  plt.title('Mask Predicted')
  plt.imshow(predicted_mask_train[i])
  plt.axis('off')

  plt.show()


# # # # Checking for overfit 
# loss function and accuracy trends of training vs validation

acc = results.history['accuracy']
val_acc = results.history['val_accuracy']


loss = results.history['loss']
val_loss = results.history['val_loss']

epochs = range(50)


fig = plt.figure()
fig.set_figheight(10)
fig.set_figwidth(20)

plt.subplot(1, 2, 1)
plt.plot(epochs, acc, label='Training Accuracy')
plt.plot(epochs, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs, loss, label='Training Loss')
plt.plot(epochs, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()



!mkdir -p /content/drive/MyDrive/saved_model
model.save('/content/drive/MyDrive/saved_model/my_model')
# model.save('/content/drive/MyDrive')


  
